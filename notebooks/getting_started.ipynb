{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting - Getting Started\n",
    "\n",
    "This notebook demonstrates how to use the time series forecasting models for the Hull Tactical Market Prediction competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import TimeSeriesPreprocessor, split_time_series\n",
    "from models import (\n",
    "    XGBoostTimeSeriesModel,\n",
    "    LightGBMTimeSeriesModel,\n",
    "    CatBoostTimeSeriesModel,\n",
    "    ProphetTimeSeriesModel,\n",
    "    ChronosTimeSeriesModel\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Parse dates\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "train_df = train_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Data shape: {train_df.shape}\")\n",
    "print(f\"\\nDate range: {train_df['date'].min()} to {train_df['date'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_df['date'], train_df['target'])\n",
    "plt.title('Time Series Plot', fontsize=16)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessor\n",
    "preprocessor = TimeSeriesPreprocessor(scaler_type='standard')\n",
    "\n",
    "# Create all features\n",
    "df_features = preprocessor.create_all_features(\n",
    "    train_df,\n",
    "    target_col='target',\n",
    "    lags=[1, 2, 3, 5, 7, 14, 21, 30],\n",
    "    windows=[7, 14, 30, 60]\n",
    ")\n",
    "\n",
    "print(f\"Features shape: {df_features.shape}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "print(df_features.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_data, val_data = split_time_series(df_features, test_size=0.2)\n",
    "\n",
    "print(f\"Train set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "\n",
    "# Prepare features and targets\n",
    "feature_cols = [col for col in df_features.columns if col not in ['date', 'target']]\n",
    "\n",
    "X_train = train_data[feature_cols].values\n",
    "y_train = train_data['target'].values\n",
    "X_val = val_data[feature_cols].values\n",
    "y_val = val_data['target'].values\n",
    "\n",
    "# Scale features\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Models\n",
    "\n",
    "### 5.1 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "xgb_model = XGBoostTimeSeriesModel()\n",
    "xgb_metrics = xgb_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"  Train RMSE: {xgb_metrics['train_rmse']:.6f}\")\n",
    "print(f\"  Val RMSE: {xgb_metrics['val_rmse']:.6f}\")\n",
    "print(f\"  Val MAE: {xgb_metrics['val_mae']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM\n",
    "lgb_model = LightGBMTimeSeriesModel()\n",
    "lgb_metrics = lgb_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\nLightGBM Results:\")\n",
    "print(f\"  Train RMSE: {lgb_metrics['train_rmse']:.6f}\")\n",
    "print(f\"  Val RMSE: {lgb_metrics['val_rmse']:.6f}\")\n",
    "print(f\"  Val MAE: {lgb_metrics['val_mae']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CatBoost\n",
    "cat_model = CatBoostTimeSeriesModel()\n",
    "cat_metrics = cat_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\nCatBoost Results:\")\n",
    "print(f\"  Train RMSE: {cat_metrics['train_rmse']:.6f}\")\n",
    "print(f\"  Val RMSE: {cat_metrics['val_rmse']:.6f}\")\n",
    "print(f\"  Val MAE: {cat_metrics['val_mae']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet\n",
    "prophet_model = ProphetTimeSeriesModel()\n",
    "prophet_train = prophet_model.prepare_data(train_data, 'date', 'target')\n",
    "prophet_val = prophet_model.prepare_data(val_data, 'date', 'target')\n",
    "\n",
    "# Train Prophet\n",
    "prophet_metrics = prophet_model.train(prophet_train, verbose=False)\n",
    "\n",
    "# Validate\n",
    "val_forecast = prophet_model.predict(prophet_val[['ds']])\n",
    "val_rmse = np.sqrt(np.mean((val_forecast['yhat'].values - prophet_val['y'].values)**2))\n",
    "val_mae = np.mean(np.abs(val_forecast['yhat'].values - prophet_val['y'].values))\n",
    "\n",
    "print(\"\\nProphet Results:\")\n",
    "print(f\"  Train RMSE: {prophet_metrics['train_rmse']:.6f}\")\n",
    "print(f\"  Val RMSE: {val_rmse:.6f}\")\n",
    "print(f\"  Val MAE: {val_mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'LightGBM', 'CatBoost', 'Prophet'],\n",
    "    'Val RMSE': [\n",
    "        xgb_metrics['val_rmse'],\n",
    "        lgb_metrics['val_rmse'],\n",
    "        cat_metrics['val_rmse'],\n",
    "        val_rmse\n",
    "    ],\n",
    "    'Val MAE': [\n",
    "        xgb_metrics['val_mae'],\n",
    "        lgb_metrics['val_mae'],\n",
    "        cat_metrics['val_mae'],\n",
    "        val_mae\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Val RMSE')\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "comparison_df.plot(x='Model', y='Val RMSE', kind='bar', ax=axes[0], legend=False)\n",
    "axes[0].set_title('Validation RMSE Comparison', fontsize=14)\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "comparison_df.plot(x='Model', y='Val MAE', kind='bar', ax=axes[1], legend=False, color='orange')\n",
    "axes[1].set_title('Validation MAE Comparison', fontsize=14)\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = xgb_model.get_feature_importance(top_n=15)\n",
    "importance_df['feature_name'] = [feature_cols[i] for i in importance_df['feature']]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "plt.yticks(range(len(importance_df)), importance_df['feature_name'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Feature Importance (XGBoost)', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from all models\n",
    "xgb_pred = xgb_model.predict(X_val)\n",
    "lgb_pred = lgb_model.predict(X_val)\n",
    "cat_pred = cat_model.predict(X_val)\n",
    "\n",
    "# Ensemble prediction (simple average)\n",
    "ensemble_pred = (xgb_pred + lgb_pred + cat_pred) / 3\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(val_data['date'].values, y_val, label='Actual', linewidth=2, alpha=0.8)\n",
    "plt.plot(val_data['date'].values, xgb_pred, label='XGBoost', alpha=0.6)\n",
    "plt.plot(val_data['date'].values, lgb_pred, label='LightGBM', alpha=0.6)\n",
    "plt.plot(val_data['date'].values, cat_pred, label='CatBoost', alpha=0.6)\n",
    "plt.plot(val_data['date'].values, ensemble_pred, label='Ensemble', linewidth=2, linestyle='--')\n",
    "plt.title('Model Predictions vs Actual', fontsize=16)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target Value')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate ensemble RMSE\n",
    "ensemble_rmse = np.sqrt(np.mean((ensemble_pred - y_val)**2))\n",
    "print(f\"\\nEnsemble RMSE: {ensemble_rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('../trained_models', exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "xgb_model.save_model('../trained_models/xgboost_model.json')\n",
    "lgb_model.save_model('../trained_models/lightgbm_model.txt')\n",
    "cat_model.save_model('../trained_models/catboost_model.cbm')\n",
    "prophet_model.save_model('../trained_models/prophet_model.pkl')\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(preprocessor, '../trained_models/preprocessor.pkl')\n",
    "\n",
    "print(\"All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "1. **Hyperparameter Tuning**: Use the `optimize_hyperparameters()` method to find better parameters\n",
    "2. **Chronos Model**: Try the Chronos-2 foundation model for zero-shot forecasting\n",
    "3. **Ensemble Optimization**: Optimize ensemble weights using validation data\n",
    "4. **Feature Engineering**: Add domain-specific features (holidays, events, etc.)\n",
    "5. **Cross-validation**: Implement time series cross-validation for robust evaluation\n",
    "\n",
    "Good luck with the competition! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
