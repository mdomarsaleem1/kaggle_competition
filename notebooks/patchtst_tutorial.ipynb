{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST: Patch-based Time Series Transformer\n",
    "\n",
    "## ðŸ“š Overview\n",
    "\n",
    "**PatchTST** (\"A Time Series is Worth 64 Words\") is a state-of-the-art transformer model from ICLR 2023.\n",
    "\n",
    "### Key Innovation\n",
    "- Treats time series as **patches** (similar to Vision Transformers)\n",
    "- Reduces sequence length by 8x â†’ more efficient training\n",
    "- Achieves **SOTA performance** on long-term forecasting benchmarks\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "Time Series [96] â†’ Patches [12 x 8] â†’ Transformer â†’ Predictions [24]\n",
    "```\n",
    "\n",
    "### Performance\n",
    "- **+40%** improvement vs standard Transformer\n",
    "- **+15%** improvement vs previous SOTA\n",
    "- Works well on both univariate and multivariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from models import PatchTSTTimeSeriesModel\n",
    "from utils.data_utils import TimeSeriesPreprocessor\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "# Expected format: CSV with 'date' column and target column\n",
    "data_path = '../data/train.csv'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Data file not found at {data_path}\")\n",
    "    print(\"Creating synthetic data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic time series\n",
    "    n_points = 1000\n",
    "    dates = pd.date_range('2020-01-01', periods=n_points, freq='D')\n",
    "    \n",
    "    # Trend + Seasonality + Noise\n",
    "    trend = np.linspace(100, 200, n_points)\n",
    "    seasonality = 20 * np.sin(2 * np.pi * np.arange(n_points) / 365)\n",
    "    noise = np.random.normal(0, 5, n_points)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'target': trend + seasonality + noise\n",
    "    })\n",
    "    print(f\"Created synthetic data with shape: {df.shape}\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df['target'].values)\n",
    "plt.title('Time Series Data', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Prepare Data for PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target values\n",
    "target_col = 'target'\n",
    "data = df[target_col].values\n",
    "\n",
    "# Reshape for model (samples, features)\n",
    "if data.ndim == 1:\n",
    "    data = data.reshape(-1, 1)\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "# Train/validation split (80/20)\n",
    "split_idx = int(len(data) * 0.8)\n",
    "train_data = data[:split_idx]\n",
    "val_data = data[split_idx:]\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Initialize PatchTST Model\n",
    "\n",
    "### Hyperparameters\n",
    "- **seq_len**: Input sequence length (e.g., 96 = ~3 months of daily data)\n",
    "- **pred_len**: Forecast horizon (e.g., 24 = 24 days)\n",
    "- **patch_len**: Length of each patch (default: 16)\n",
    "- **stride**: Stride between patches (default: 8)\n",
    "- **d_model**: Dimension of model (default: 128)\n",
    "- **n_heads**: Number of attention heads (default: 8)\n",
    "- **n_layers**: Number of transformer layers (default: 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "seq_len = 96      # Input window: 96 time steps\n",
    "pred_len = 24     # Forecast: 24 time steps ahead\n",
    "n_features = data.shape[1]  # Number of features (1 for univariate)\n",
    "\n",
    "# Initialize PatchTST\n",
    "model = PatchTSTTimeSeriesModel(\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    n_features=n_features,\n",
    "    patch_len=16,        # Each patch is 16 time steps\n",
    "    stride=8,            # 50% overlap between patches\n",
    "    d_model=128,         # Model dimension\n",
    "    n_heads=8,           # 8 attention heads\n",
    "    n_layers=3,          # 3 transformer layers\n",
    "    d_ff=256,            # Feed-forward dimension\n",
    "    dropout=0.1,\n",
    "    epochs=50,           # Training epochs\n",
    "    batch_size=32,\n",
    "    learning_rate=0.001,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nPatchTST Model Initialized\")\n",
    "print(f\"Input: {seq_len} time steps\")\n",
    "print(f\"Output: {pred_len} time steps\")\n",
    "print(f\"Patches: {(seq_len - 16) // 8 + 1} patches of length 16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PatchTST\n",
    "print(\"Training PatchTST...\")\n",
    "metrics = model.train(train_data, val_data, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Final Validation RMSE: {metrics.get('val_rmse', 'N/A'):.4f}\")\n",
    "print(f\"Final Validation MAE: {metrics.get('val_mae', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_losses' in metrics and 'val_losses' in metrics:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Training and validation loss\n",
    "    ax1.plot(metrics['train_losses'], label='Training Loss', linewidth=2)\n",
    "    ax1.plot(metrics['val_losses'], label='Validation Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss (MSE)', fontsize=12)\n",
    "    ax1.set_title('Training History', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning curve\n",
    "    best_epoch = np.argmin(metrics['val_losses'])\n",
    "    ax2.axvline(best_epoch, color='r', linestyle='--', label=f'Best Epoch: {best_epoch}')\n",
    "    ax2.plot(metrics['val_losses'], linewidth=2, color='orange')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Validation Loss', fontsize=12)\n",
    "    ax2.set_title('Validation Loss Curve', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”® Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation data\n",
    "predictions = model.predict(val_data, return_sequences=False)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"First 5 predictions: {predictions[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ground truth values\n",
    "# For each prediction, the ground truth is pred_len steps ahead\n",
    "n_samples = min(len(predictions), len(val_data) - pred_len)\n",
    "ground_truth = []\n",
    "for i in range(n_samples):\n",
    "    ground_truth.append(val_data[i + pred_len, 0])\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "# Truncate predictions if needed\n",
    "predictions_plot = predictions[:n_samples]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot ground truth and predictions\n",
    "plt.plot(ground_truth, label='Ground Truth', linewidth=2, alpha=0.7)\n",
    "plt.plot(predictions_plot, label='PatchTST Predictions', linewidth=2, alpha=0.7)\n",
    "\n",
    "plt.title(f'PatchTST Forecasts (Horizon: {pred_len} steps)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Sample', fontsize=12)\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = np.mean(np.abs(ground_truth - predictions_plot))\n",
    "rmse = np.sqrt(np.mean((ground_truth - predictions_plot) ** 2))\n",
    "mape = np.mean(np.abs((ground_truth - predictions_plot) / (ground_truth + 1e-8))) * 100\n",
    "\n",
    "print(f\"\\nPrediction Metrics:\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Detailed Forecast Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a specific window and forecast\n",
    "test_idx = 0\n",
    "context = val_data[test_idx:test_idx + seq_len]\n",
    "\n",
    "# Make forecast\n",
    "forecast = model.predict(context.reshape(1, -1, 1))\n",
    "if forecast.ndim > 1:\n",
    "    forecast = forecast[0]\n",
    "\n",
    "# Get actual future values\n",
    "actual_future = val_data[test_idx + seq_len:test_idx + seq_len + pred_len, 0]\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Historical context\n",
    "ax1.plot(range(seq_len), context[:, 0], label='Historical Context', linewidth=2)\n",
    "ax1.axvline(seq_len - 1, color='red', linestyle='--', alpha=0.5, label='Forecast Start')\n",
    "ax1.set_title('Input Context (Historical Data)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Time Step', fontsize=12)\n",
    "ax1.set_ylabel('Value', fontsize=12)\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Forecast vs actual\n",
    "forecast_range = range(seq_len, seq_len + pred_len)\n",
    "ax2.plot(range(seq_len), context[:, 0], label='Historical Context', linewidth=2, alpha=0.5)\n",
    "ax2.plot(forecast_range, actual_future, 'g-', label='Actual Future', linewidth=2, marker='o')\n",
    "ax2.plot(forecast_range, forecast, 'r--', label='PatchTST Forecast', linewidth=2, marker='s')\n",
    "ax2.axvline(seq_len - 1, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.set_title('Forecast vs Actual', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Time Step', fontsize=12)\n",
    "ax2.set_ylabel('Value', fontsize=12)\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Forecast error\n",
    "forecast_mae = np.mean(np.abs(actual_future - forecast))\n",
    "print(f\"\\nForecast MAE: {forecast_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = '../trained_models/patchtst_model.pth'\n",
    "os.makedirs('../trained_models', exist_ok=True)\n",
    "\n",
    "model.save_model(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Load and Use Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "loaded_model = PatchTSTTimeSeriesModel(\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    n_features=n_features,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "loaded_model.load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions with loaded model\n",
    "loaded_predictions = loaded_model.predict(context.reshape(1, -1, 1))\n",
    "print(f\"\\nPredictions from loaded model: {loaded_predictions[0][:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "### PatchTST Advantages\n",
    "1. **Efficiency**: 8x faster training than standard Transformers\n",
    "2. **Performance**: SOTA results on long-term forecasting\n",
    "3. **Flexibility**: Works with both univariate and multivariate data\n",
    "4. **Scalability**: Can handle long sequences efficiently\n",
    "\n",
    "### When to Use PatchTST\n",
    "- âœ… Long-term forecasting (24+ steps ahead)\n",
    "- âœ… High-frequency data (hourly, daily)\n",
    "- âœ… When you have sufficient training data (1000+ samples)\n",
    "- âœ… When computational efficiency matters\n",
    "\n",
    "### Hyperparameter Tuning Tips\n",
    "- **patch_len**: Larger patches â†’ fewer patches â†’ faster training\n",
    "- **stride**: Smaller stride â†’ more patches â†’ better accuracy (but slower)\n",
    "- **d_model**: Larger model â†’ more capacity (but needs more data)\n",
    "- **n_layers**: 3-5 layers usually optimal\n",
    "\n",
    "### Next Steps\n",
    "1. Try different patch configurations\n",
    "2. Experiment with multivariate data\n",
    "3. Compare with other models (iTransformer, TimesNet)\n",
    "4. Use in ensemble with other models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
