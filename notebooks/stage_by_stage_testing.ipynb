{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage-by-Stage Testing Notebook\n",
        "\n",
        "This notebook walks through each step of the time-series workflow so you can validate changes incrementally:\n",
        "\n",
        "1. Load and inspect the training/test data.\n",
        "2. Build **10 chronological cross-validation folds**.\n",
        "3. Add a numeric date index alongside your features.\n",
        "4. Train a lightweight baseline model fold-by-fold.\n",
        "5. Aggregate validation metrics and train a final model for submission.\n",
        "\n",
        "Configure the paths and columns in the **Configuration** cell, then execute the rest of the notebook top-to-bottom.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "- Place your CSVs in the `data/` directory (or update the paths below).\n",
        "- Ensure dependencies from `requirements.txt` are installed: `pip install -r requirements.txt`.\n",
        "- If you want GPU acceleration for LightGBM/transformers, install the appropriate extras and set the device flags in the model constructors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Make the project importable when running the notebook from the notebooks/ folder\n",
        "PROJECT_ROOT = Path('..').resolve()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 120)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Configuration\n",
        "Update the file names and column names to match your dataset before running the rest of the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_DIR = Path('../data')\n",
        "TRAIN_FILE = DATA_DIR / 'train.csv'   # update if your file name differs\n",
        "TEST_FILE = DATA_DIR / 'test.csv'     # set to a CSV path if you have a test set\n",
        "TARGET_COL = 'target'                 # change to the name of your target column\n",
        "DATE_COL = 'date'                     # change to your datetime column (or set to None)\n",
        "N_SPLITS = 10                         # number of chronological folds\n",
        "FOLD_OUTPUT = DATA_DIR / 'cv_folds'   # where to persist fold CSVs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load data\n",
        "\n",
        "The helper below parses and sorts the date column so folds and models respect chronology.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from utils.data_utils import TimeSeriesPreprocessor\n",
        "\n",
        "preprocessor = TimeSeriesPreprocessor(scaler_type=None)\n",
        "\n",
        "train_df, test_df = preprocessor.load_data(TRAIN_FILE, TEST_FILE if TEST_FILE.exists() else None)\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "if test_df is not None:\n",
        "    print(f\"Test shape:  {test_df.shape}\")\n",
        "\n",
        "train_df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Create chronological folds\n",
        "\n",
        "The folds are time-ordered using `TimeSeriesSplit` and can be saved to disk for re-use across models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from utils.cross_validation import create_chronological_folds, save_folds_to_disk\n",
        "\n",
        "folds = create_chronological_folds(train_df, n_splits=N_SPLITS, date_col=DATE_COL)\n",
        "for fold in folds:\n",
        "    print(f\"Fold {fold.fold_id}: train {fold.train_range} | test {fold.test_range}\")\n",
        "\n",
        "# Persist the fold CSVs so other scripts can consume the same splits\n",
        "save_folds_to_disk(folds, FOLD_OUTPUT)\n",
        "print(f\"Folds saved under: {FOLD_OUTPUT.resolve()}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Feature engineering with numeric date indices\n",
        "\n",
        "The helper below converts the datetime column to an ordinal integer (days since year 1) so transformers and\n",
        "tree models consume a numeric representation instead of raw timestamps. Add your own domain features as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def add_date_ordinal(df: pd.DataFrame, date_col: str):\n",
        "    df_out = df.copy()\n",
        "    if date_col and date_col in df_out.columns:\n",
        "        df_out[date_col] = pd.to_datetime(df_out[date_col])\n",
        "        df_out['date_ordinal'] = df_out[date_col].dt.toordinal()\n",
        "    return df_out\n",
        "\n",
        "\n",
        "def build_feature_matrix(df: pd.DataFrame, target_col: str, date_col: str):\n",
        "    # Return feature matrix, target array, and feature column names.\n",
        "    df_feat = add_date_ordinal(df, date_col)\n",
        "    feature_cols = [c for c in df_feat.columns if c not in {target_col, date_col}]\n",
        "    X = df_feat[feature_cols].values\n",
        "    y = df_feat[target_col].values if target_col in df_feat else None\n",
        "    return X, y, feature_cols\n",
        "\n",
        "# Quick sanity check on the transformed columns\n",
        "sample_with_ordinal = add_date_ordinal(train_df.head(), DATE_COL)\n",
        "sample_with_ordinal[[col for col in sample_with_ordinal.columns if 'date' in col]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Fold-by-fold training (LightGBM example)\n",
        "\n",
        "This section trains a lightweight LightGBM regressor on each fold to validate the pipeline. Adjust the\n",
        "model or hyperparameters as needed for your experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from models import LightGBMTimeSeriesModel\n",
        "\n",
        "fold_metrics = []\n",
        "\n",
        "for fold in folds:\n",
        "    X_train, y_train, feature_cols = build_feature_matrix(fold.train, TARGET_COL, DATE_COL)\n",
        "    X_val, y_val, _ = build_feature_matrix(fold.test, TARGET_COL, DATE_COL)\n",
        "\n",
        "    model = LightGBMTimeSeriesModel(\n",
        "        params={\n",
        "            'n_estimators': 250,\n",
        "            'learning_rate': 0.05,\n",
        "            'num_leaves': 63,\n",
        "            'subsample': 0.9,\n",
        "            'colsample_bytree': 0.9,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    metrics = model.train(X_train, y_train, X_val, y_val, verbose=False)\n",
        "    fold_metrics.append({\n",
        "        'fold': fold.fold_id,\n",
        "        'val_rmse': metrics.get('val_rmse'),\n",
        "        'val_mae': metrics.get('val_mae'),\n",
        "        'best_iteration': metrics.get('best_iteration')\n",
        "    })\n",
        "\n",
        "    print(\n",
        "        f\"Fold {fold.fold_id} \u2192 val_rmse: {metrics.get('val_rmse'):.5f}, \"\n",
        "        f\"val_mae: {metrics.get('val_mae'):.5f}, best_iter: {metrics.get('best_iteration')}\"\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Aggregate validation metrics\n",
        "\n",
        "Inspect the per-fold metrics and the average validation score. You can use these to compare different\n",
        "feature sets or models while keeping the folds fixed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metrics_df = pd.DataFrame(fold_metrics)\n",
        "\n",
        "        display(metrics_df)\n",
        "        print(\"\n",
        "Average val RMSE:\", metrics_df['val_rmse'].mean())\n",
        "        print(\"Average val MAE: \", metrics_df['val_mae'].mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Train on full data and generate submission-ready predictions\n",
        "\n",
        "This cell refits the model on the entire training set (with the same numeric date features) and produces\n",
        "predictions for the test set. Adjust the submission schema to match the competition requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if test_df is None:\n",
        "    print(\"No test file found. Skipping final training and prediction.\")\n",
        "else:\n",
        "    X_full, y_full, feature_cols = build_feature_matrix(train_df, TARGET_COL, DATE_COL)\n",
        "    X_test, _, _ = build_feature_matrix(test_df, TARGET_COL, DATE_COL)\n",
        "\n",
        "    final_model = LightGBMTimeSeriesModel(\n",
        "        params={\n",
        "            'n_estimators': 400,\n",
        "            'learning_rate': 0.03,\n",
        "            'num_leaves': 127,\n",
        "            'subsample': 0.9,\n",
        "            'colsample_bytree': 0.9,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    final_model.train(X_full, y_full, verbose=False)\n",
        "    test_pred = final_model.predict(X_test)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        'row_id': np.arange(len(test_pred)),\n",
        "        TARGET_COL: test_pred\n",
        "    })\n",
        "\n",
        "    submission_path = DATA_DIR / 'submission_stage_testing.csv'\n",
        "    submission.to_csv(submission_path, index=False)\n",
        "    print(f\"Saved submission to {submission_path.resolve()}\")\n",
        "    submission.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}