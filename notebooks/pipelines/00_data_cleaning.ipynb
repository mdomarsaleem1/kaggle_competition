{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00 - Data cleaning and fold generation",
        "",
        "This notebook ingests raw Kaggle data from `data/01_raw`, applies light cleaning, and materializes fold definitions for all downstream model notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path",
        "",
        "import pandas as pd",
        "from utils import (",
        "    TimeSeriesPreprocessor,",
        "    create_chronological_folds,",
        "    default_catalog,",
        "    save_folds_to_disk,",
        "    save_table,",
        ")",
        "",
        "catalog = default_catalog()",
        "train_path = catalog[\"train_raw\"]",
        "test_path = catalog[\"test_raw\"]",
        "",
        "preprocessor = TimeSeriesPreprocessor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load raw data",
        "The Kedro-style catalog keeps paths centralized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if train_path.exists():",
        "    train_df, test_df = preprocessor.load_data(train_path, test_path)",
        "    print(train_df.head())",
        "else:",
        "    train_df, test_df = None, None",
        "    print(f\"No raw data found at {train_path}. Add files to data/01_raw.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean and engineer features",
        "Use the preprocessor to generate lag/rolling windows and fill missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if train_df is not None:",
        "    base_features = preprocessor.create_all_features(train_df, target_col='target', lags=[1,2,3,5,7,14], windows=[7,14,30])",
        "    clean_df = base_features.fillna(method='ffill').dropna()",
        "    save_table(clean_df, catalog['clean_train'])",
        "    print(f\"Saved cleaned training data -> {catalog['clean_train']}\")",
        "else:",
        "    print('Skipping feature generation because training data is missing.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chronological folds",
        "Create ten splits to be reused across all model notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if train_df is not None:",
        "    folds = create_chronological_folds(clean_df, n_splits=10, date_col='date')",
        "    save_folds_to_disk(folds, catalog['folds_dir'])",
        "else:",
        "    print('Cannot create folds without cleaned data.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}