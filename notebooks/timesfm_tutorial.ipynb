{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimesFM: Google's Time Series Foundation Model\n",
    "\n",
    "## ðŸ“š Overview\n",
    "\n",
    "**TimesFM** is Google's decoder-only transformer foundation model for time series forecasting.\n",
    "\n",
    "### Key Features\n",
    "- **Pre-trained on 100 billion time points** from real-world data\n",
    "- **Decoder-only architecture** (GPT-style for time series)\n",
    "- **Zero-shot forecasting** capability\n",
    "- **Long context length** (up to 512 time steps)\n",
    "- **Efficient patched-attention** mechanism\n",
    "\n",
    "### TimesFM vs Chronos-2\n",
    "\n",
    "| Feature | TimesFM | Chronos-2 |\n",
    "|---------|---------|----------|\n",
    "| Architecture | Decoder-only (GPT-style) | Encoder-only (BERT-style) |\n",
    "| Pre-training | 100B time points | 100K+ time series |\n",
    "| Approach | Autoregressive generation | Masked modeling |\n",
    "| Context Length | Up to 512 | Variable |\n",
    "\n",
    "### When to Use TimesFM\n",
    "- âœ… Limited training data (zero-shot capability)\n",
    "- âœ… New domains without historical patterns\n",
    "- âœ… Need for uncertainty quantification\n",
    "- âœ… Quick baseline without training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from models import TimesFMTimeSeriesModel\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if official TimesFM is available\n",
    "try:\n",
    "    import timesfm\n",
    "    print(\"âœ… Official TimesFM package available\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  Official TimesFM not found - using custom fallback implementation\")\n",
    "    print(\"   Install with: pip install timesfm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "data_path = '../data/train.csv'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Data file not found at {data_path}\")\n",
    "    print(\"Creating synthetic data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic time series with multiple patterns\n",
    "    n_points = 1000\n",
    "    dates = pd.date_range('2020-01-01', periods=n_points, freq='D')\n",
    "    \n",
    "    # Complex pattern: Trend + Multiple seasonalities + Noise\n",
    "    trend = np.linspace(100, 200, n_points)\n",
    "    yearly_seasonality = 30 * np.sin(2 * np.pi * np.arange(n_points) / 365)\n",
    "    monthly_seasonality = 10 * np.sin(2 * np.pi * np.arange(n_points) / 30)\n",
    "    weekly_seasonality = 5 * np.sin(2 * np.pi * np.arange(n_points) / 7)\n",
    "    noise = np.random.normal(0, 5, n_points)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'target': trend + yearly_seasonality + monthly_seasonality + weekly_seasonality + noise\n",
    "    })\n",
    "    print(f\"Created synthetic data with shape: {df.shape}\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Full time series\n",
    "ax1.plot(df['target'].values, linewidth=1.5)\n",
    "ax1.set_title('Complete Time Series', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Time Step')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Last 200 points (zoomed in)\n",
    "ax2.plot(df['target'].values[-200:], linewidth=2, color='orange')\n",
    "ax2.set_title('Last 200 Time Steps (Zoomed)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Time Step')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Prepare Data for TimesFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target values\n",
    "target_col = 'target'\n",
    "data = df[target_col].values\n",
    "\n",
    "# Reshape for model\n",
    "if data.ndim == 1:\n",
    "    data = data.reshape(-1, 1)\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "# Train/validation split (80/20)\n",
    "split_idx = int(len(data) * 0.8)\n",
    "train_data = data[:split_idx]\n",
    "val_data = data[split_idx:]\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Initialize TimesFM Model\n",
    "\n",
    "### Model Sizes\n",
    "- **small**: ~256M dimension, 4 layers (fastest)\n",
    "- **base**: ~512M dimension, 8 layers (balanced) â­ Default\n",
    "- **large**: ~1024M dimension, 12 layers (best performance)\n",
    "\n",
    "### Key Parameters\n",
    "- **seq_len**: Context length (how much history to use)\n",
    "- **pred_len**: Forecast horizon (how far to predict)\n",
    "- **model_size**: Model capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "seq_len = 512     # TimesFM supports up to 512 context length\n",
    "pred_len = 96     # Forecast 96 steps ahead\n",
    "\n",
    "# Initialize TimesFM\n",
    "model = TimesFMTimeSeriesModel(\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    model_size='base',   # 'small', 'base', or 'large'\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nTimesFM Model Initialized\")\n",
    "print(f\"Model size: base\")\n",
    "print(f\"Context length: {seq_len} time steps\")\n",
    "print(f\"Forecast horizon: {pred_len} time steps\")\n",
    "print(f\"\\nâ­ TimesFM is pre-trained - no training required!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ \"Train\" the Model\n",
    "\n",
    "**Note:** TimesFM is pre-trained, so this step just evaluates the model on your data.\n",
    "It doesn't actually train - it assesses zero-shot performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate TimesFM (zero-shot)\n",
    "print(\"Evaluating TimesFM on your data...\")\n",
    "print(\"(This is zero-shot evaluation - no training!)\")\n",
    "\n",
    "metrics = model.train(train_data, val_data, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Zero-Shot Evaluation Complete!\")\n",
    "print(\"=\"*50)\n",
    "if 'val_rmse' in metrics:\n",
    "    print(f\"Validation RMSE: {metrics['val_rmse']:.4f}\")\n",
    "if 'val_mae' in metrics:\n",
    "    print(f\"Validation MAE: {metrics['val_mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”® Make Zero-Shot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation data\n",
    "print(\"Making zero-shot predictions...\")\n",
    "predictions = model.predict(val_data[:seq_len])\n",
    "\n",
    "print(f\"\\nPredictions shape: {predictions.shape}\")\n",
    "print(f\"First 10 predictions: {predictions[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Visualize Zero-Shot Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a window from validation data\n",
    "test_idx = 0\n",
    "context = val_data[test_idx:test_idx + seq_len]\n",
    "\n",
    "# Make forecast\n",
    "forecast = model.predict(context)\n",
    "if forecast.ndim > 1 and forecast.shape[0] == 1:\n",
    "    forecast = forecast[0]\n",
    "\n",
    "# Get actual future values\n",
    "if test_idx + seq_len + pred_len <= len(val_data):\n",
    "    actual_future = val_data[test_idx + seq_len:test_idx + seq_len + pred_len, 0]\n",
    "else:\n",
    "    actual_future = val_data[test_idx + seq_len:, 0]\n",
    "    # Pad if necessary\n",
    "    if len(actual_future) < pred_len:\n",
    "        forecast = forecast[:len(actual_future)]\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Historical context\n",
    "ax1.plot(range(len(context)), context[:, 0], label='Historical Context', linewidth=2, color='blue')\n",
    "ax1.axvline(len(context) - 1, color='red', linestyle='--', alpha=0.5, label='Forecast Start')\n",
    "ax1.set_title('Input Context for TimesFM', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Time Step', fontsize=12)\n",
    "ax1.set_ylabel('Value', fontsize=12)\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Zero-shot forecast vs actual\n",
    "forecast_range = range(len(context), len(context) + len(actual_future))\n",
    "ax2.plot(range(len(context)), context[:, 0], label='Historical Context', linewidth=2, alpha=0.3, color='blue')\n",
    "ax2.plot(forecast_range, actual_future, 'g-', label='Actual Future', linewidth=2.5, marker='o', markersize=4)\n",
    "ax2.plot(forecast_range, forecast[:len(actual_future)], 'r--', label='TimesFM Zero-Shot Forecast', linewidth=2.5, marker='s', markersize=4)\n",
    "ax2.axvline(len(context) - 1, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.fill_between(forecast_range, actual_future, forecast[:len(actual_future)], alpha=0.2, color='orange')\n",
    "ax2.set_title('TimesFM Zero-Shot Forecast vs Actual', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Time Step', fontsize=12)\n",
    "ax2.set_ylabel('Value', fontsize=12)\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error\n",
    "mae = np.mean(np.abs(actual_future - forecast[:len(actual_future)]))\n",
    "rmse = np.sqrt(np.mean((actual_future - forecast[:len(actual_future)]) ** 2))\n",
    "print(f\"\\nZero-Shot Forecast Metrics:\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Compare Different Context Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different context lengths\n",
    "context_lengths = [64, 128, 256, 512]\n",
    "results = {}\n",
    "\n",
    "print(\"Testing different context lengths...\")\n",
    "for ctx_len in context_lengths:\n",
    "    if ctx_len > len(val_data):\n",
    "        continue\n",
    "    \n",
    "    # Create model with different context length\n",
    "    temp_model = TimesFMTimeSeriesModel(\n",
    "        seq_len=ctx_len,\n",
    "        pred_len=pred_len,\n",
    "        model_size='base',\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Make prediction\n",
    "    context = val_data[:ctx_len]\n",
    "    forecast = temp_model.predict(context)\n",
    "    \n",
    "    # Calculate error\n",
    "    actual = val_data[ctx_len:ctx_len + pred_len, 0]\n",
    "    if len(actual) > 0:\n",
    "        forecast_trimmed = forecast[:len(actual)] if forecast.ndim == 1 else forecast[0, :len(actual)]\n",
    "        mae = np.mean(np.abs(actual - forecast_trimmed))\n",
    "        results[ctx_len] = mae\n",
    "        print(f\"Context length {ctx_len:3d}: MAE = {mae:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "if results:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(list(results.keys()), list(results.values()), marker='o', linewidth=2, markersize=10)\n",
    "    plt.xlabel('Context Length', fontsize=12)\n",
    "    plt.ylabel('MAE', fontsize=12)\n",
    "    plt.title('Impact of Context Length on Forecast Accuracy', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    best_ctx = min(results, key=results.get)\n",
    "    print(f\"\\nâœ… Best context length: {best_ctx} (MAE: {results[best_ctx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model configuration\n",
    "model_path = '../trained_models/timesfm_config.json'\n",
    "os.makedirs('../trained_models', exist_ok=True)\n",
    "\n",
    "model.save_model(model_path)\n",
    "print(f\"Model configuration saved to {model_path}\")\n",
    "print(\"\\nNote: TimesFM is pre-trained, so we only save configuration.\")\n",
    "print(\"The actual model weights are loaded from the pre-trained checkpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Load Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = TimesFMTimeSeriesModel(\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    model_size='base',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "loaded_model.load_model(model_path)\n",
    "print(\"Model configuration loaded successfully!\")\n",
    "\n",
    "# Test loaded model\n",
    "test_forecast = loaded_model.predict(val_data[:seq_len])\n",
    "print(f\"\\nTest prediction from loaded model: {test_forecast[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ†š Compare TimesFM with Simple Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple baseline: Naive forecast (repeat last value)\n",
    "context = val_data[:seq_len]\n",
    "naive_forecast = np.full(pred_len, context[-1, 0])\n",
    "\n",
    "# TimesFM forecast\n",
    "timesfm_forecast = model.predict(context)\n",
    "if timesfm_forecast.ndim > 1:\n",
    "    timesfm_forecast = timesfm_forecast[0]\n",
    "\n",
    "# Actual values\n",
    "actual = val_data[seq_len:seq_len + pred_len, 0]\n",
    "if len(actual) < pred_len:\n",
    "    naive_forecast = naive_forecast[:len(actual)]\n",
    "    timesfm_forecast = timesfm_forecast[:len(actual)]\n",
    "\n",
    "# Calculate errors\n",
    "naive_mae = np.mean(np.abs(actual - naive_forecast))\n",
    "timesfm_mae = np.mean(np.abs(actual - timesfm_forecast))\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(15, 6))\n",
    "forecast_range = range(len(actual))\n",
    "\n",
    "plt.plot(forecast_range, actual, 'g-', label='Actual', linewidth=2.5, marker='o', markersize=5)\n",
    "plt.plot(forecast_range, naive_forecast, 'gray', linestyle=':', label=f'Naive (MAE: {naive_mae:.2f})', linewidth=2)\n",
    "plt.plot(forecast_range, timesfm_forecast, 'r--', label=f'TimesFM (MAE: {timesfm_mae:.2f})', linewidth=2.5, marker='s', markersize=4)\n",
    "\n",
    "plt.title('TimesFM vs Naive Baseline', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Forecast Step', fontsize=12)\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "improvement = ((naive_mae - timesfm_mae) / naive_mae) * 100\n",
    "print(f\"\\nðŸ“Š Comparison Results:\")\n",
    "print(f\"Naive Baseline MAE: {naive_mae:.4f}\")\n",
    "print(f\"TimesFM MAE: {timesfm_mae:.4f}\")\n",
    "print(f\"\\nâœ… TimesFM improvement: {improvement:.1f}% better than naive baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "### TimesFM Advantages\n",
    "1. **Zero-Shot**: No training required - works out of the box!\n",
    "2. **Pre-trained**: Learned from 100B time points across diverse domains\n",
    "3. **Fast**: Immediate predictions without waiting for training\n",
    "4. **Versatile**: Works on various time series types\n",
    "5. **Long Context**: Can use up to 512 historical points\n",
    "\n",
    "### When to Use TimesFM\n",
    "- âœ… **Limited data**: When you have few training samples\n",
    "- âœ… **Quick baseline**: Need fast results without training\n",
    "- âœ… **New domains**: No domain-specific historical data\n",
    "- âœ… **Transfer learning**: Leverage world knowledge\n",
    "- âœ… **Ensemble member**: Combine with domain-specific models\n",
    "\n",
    "### TimesFM vs Other Models\n",
    "\n",
    "| Model | Training Needed | Best For |\n",
    "|-------|----------------|----------|\n",
    "| TimesFM | âŒ No (pre-trained) | Zero-shot, quick baseline |\n",
    "| Chronos-2 | âŒ No (pre-trained) | Similar to TimesFM |\n",
    "| PatchTST | âœ… Yes | Dataset-specific patterns |\n",
    "| iTransformer | âœ… Yes | Multivariate relationships |\n",
    "| XGBoost | âœ… Yes | Tabular features |\n",
    "\n",
    "### Tips for Best Results\n",
    "1. **Context length**: Longer is often better (up to 512)\n",
    "2. **Normalization**: TimesFM handles various scales well\n",
    "3. **Ensemble**: Combine with task-specific models\n",
    "4. **Model size**: Start with 'base', use 'large' for better accuracy\n",
    "\n",
    "### Next Steps\n",
    "1. Try different model sizes (small/base/large)\n",
    "2. Experiment with context lengths\n",
    "3. Compare with other foundation models (Chronos-2)\n",
    "4. Use in ensemble with domain-specific models\n",
    "5. Evaluate on multiple datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
